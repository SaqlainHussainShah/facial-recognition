{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Reference to :\n",
    "https://towardsdatascience.com/facial-recognition-using-deep-learning-a74e9059a150\n",
    "and coursera Andrew's CNN assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import os# Get Face Detector from dlib\n",
    "# This allows us to detect faces in images\n",
    "face_detector = dlib.get_frontal_face_detector()# Get Pose Predictor from dlib\n",
    "# This allows us to detect landmark points in faces and understand the pose/angle of the face\n",
    "shape_predictor = dlib.shape_predictor('./shape_predictor_68_face_landmarks.dat')# Get the face recognition model\n",
    "# This is what gives us the face encodings (numbers that identify the face of a particular person)\n",
    "face_recognition_model = dlib.face_recognition_model_v1('./dlib_face_recognition_resnet_model_v1.dat')# This is the tolerance for face comparisons\n",
    "# The lower the number - the stricter the comparison\n",
    "# To avoid false matches, use lower value\n",
    "# To avoid false negatives (i.e. faces of the same person doesn't match), use higher value\n",
    "# 0.5-0.6 works well\n",
    "TOLERANCE = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import cv2\n",
    "# This function will take an image and return its face encodings using the neural network\n",
    "def get_face_encodings(path_to_image):\n",
    "    # Load image using scipy\n",
    "#     from PIL import Image\n",
    "#     image = cv2.imread(path_to_image)\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #     image = scipy.misc.imread(path_to_image)  # Detect faces using the face detector\n",
    "    import matplotlib.pyplot\n",
    "    image = matplotlib.pyplot.imread(path_to_image)\n",
    "    detected_faces = face_detector(image, 1)    # Get pose/landmarks of those faces\n",
    "    # Will be used as an input to the function that computes face encodings\n",
    "    # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n",
    "    shapes_faces = [shape_predictor(image, face) for face in detected_faces]    # For every face detected, compute the face encodings\n",
    "    return [np.array(face_recognition_model.compute_face_descriptor(image, face_pose, 1)) for face_pose in shapes_faces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_img_path(label, img_path):\n",
    "    encodings = get_face_encodings(img_path)\n",
    "    database[label] = encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"buckley\"\n",
    "img_path = \"./siamese dataset/A.J._Buckley/0.jpg\"\n",
    "add_user_img_path(name, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"amir\"\n",
    "img_path = \"./siamese dataset/Aamir_Khan/2.jpg\"\n",
    "add_user_img_path( name, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"staton\"\n",
    "img_path = \"./siamese dataset/Aaron_Staton/0.jpg\"\n",
    "add_user_img_path( name, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Deyn\"\n",
    "img_path = \"./siamese dataset/Agyness_Deyn/2.jpg\"\n",
    "add_user_img_path(name, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = \"Devgn\"\n",
    "img_path = \"./siamese dataset/Ajay_Devgn/20.jpg\"\n",
    "add_user_img_path( name, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Hodge\"\n",
    "img_path = \"./siamese dataset/Aldis_Hodge/21.jpg\"\n",
    "add_user_img_path( name, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Kumar\"\n",
    "img_path = \"./siamese dataset/Akshay_Kumar/18.jpg\"\n",
    "add_user_img_path( name, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Fast\"\n",
    "img_path = \"./siamese dataset/Alexia_Fast/57.jpg\"\n",
    "add_user_img_path( name, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Daddario\"\n",
    "img_path = \"./siamese dataset/Alexandra_Daddario/57.jpg\"\n",
    "add_user_img_path( name, img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ini_user_database():\n",
    "    # check for existing database\n",
    "    if os.path.exists('database/user_dict.pickle'):\n",
    "        with open('database/user_dict.pickle', 'rb') as handle:\n",
    "            user_db = pickle.load(handle)   \n",
    "    else:\n",
    "        # make a new one\n",
    "        # we use a dict for keeping track of mapping of each person with his/her face encoding\n",
    "        user_db = {}\n",
    "        # create the directory for saving the db pickle file\n",
    "        os.makedirs('database')\n",
    "        with open('database/user_dict.pickle', 'wb') as handle:\n",
    "            pickle.dump(user_db, handle, protocol=pickle.HIGHEST_PROTOCOL)   \n",
    "    return user_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"./shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "\n",
    "def get_face(image):\n",
    "    \n",
    "\n",
    "  rects = detector(image,1)\n",
    "  if len(rects) == 1:\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for face region , then\n",
    "        # convert the facial landmark(x,y) coordinates to np array\n",
    "        shape = predictor(image, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        # convert dlib's rectangle to openCV style bounding box \n",
    "        # i.e (x,y,w,h) then draw face bounding box\n",
    "        (x,y,w,h) = face_utils.rect_to_bb(rect)\n",
    "        if x>1 and y>1:\n",
    "          face = image[y-15:y+h+15,x-15:x+w+15]\n",
    "          face = cv2.resize(face,(int(96),int(96)))\n",
    "          face = np.asarray(face)\n",
    "          plt.imshow(face)\n",
    "          face = face.reshape(1,3,96,96)\n",
    "          # print(x,y,w,h)\n",
    "      # image = cv2.resize(image,(int(128),int(128)))\n",
    "          # print(type(face))\n",
    "          return face\n",
    "  else:\n",
    "    return ''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(X,network):\n",
    "    img = cv2.imread(X)\n",
    "    img = get_face(img)\n",
    "#     img = cv2.resize(img, (int(96),int(96)))\n",
    "#     img =  cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     img = cv2.resize(image, (int(96),int(96)))\n",
    "\n",
    "#     img = img.reshape(1,3,96,96)\n",
    "    m = img.shape[0]\n",
    "    nbevaluation = int(m*(m-1)/2)\n",
    "    probs = np.zeros((nbevaluation))\n",
    "    y = np.zeros((nbevaluation))\n",
    "    \n",
    "    #Compute all embeddings for all pics with current network\n",
    "    embeddings = network.predict(img)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_face(image_path,threshold = 0.6):\n",
    "    # find the face encodings for the input image\n",
    "#     encoding = img_to_encoding(image_path, model)\n",
    "    encoding = get_face_encodings(image_path)    \n",
    "    \n",
    "    min_dist = 99999\n",
    "    # loop over all the recorded encodings in database \n",
    "    for name in database:\n",
    "        # find the similarity between the input encodings and claimed person's encodings using L2 norm\n",
    "        dist = np.linalg.norm(np.subtract(database[name], encoding) )\n",
    "        print(\"name : \", name)\n",
    "        print(\"distance \", dist)\n",
    "        # check if minimum distance or not\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "    if min_dist > threshold:\n",
    "        print(\"User not in the database.\")\n",
    "        identity = 'Unknown Person'\n",
    "    else:\n",
    "        print (\"Hi! \" + str(identity) + \", L2 distance: \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  buckley\n",
      "distance  0.9231899520706222\n",
      "name :  amir\n",
      "distance  0.6171786779369691\n",
      "name :  staton\n",
      "distance  0.9038289612913356\n",
      "name :  Deyn\n",
      "distance  0.9963270891110149\n",
      "name :  Devgn\n",
      "distance  0.3675174807497336\n",
      "name :  Hodge\n",
      "distance  0.8871550005784846\n",
      "name :  Kumar\n",
      "distance  0.7678247950491384\n",
      "name :  Fast\n",
      "distance  0.9446914045960852\n",
      "name :  Daddario\n",
      "distance  0.9911690016436425\n",
      "Hi! Devgn, L2 distance: 0.3675174807497336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3675174807497336, 'Devgn')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "find_face(image_path = \"./siamese dataset/Ajay_Devgn/2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  buckley\n",
      "distance  0.7688638451152058\n",
      "name :  amir\n",
      "distance  0.8518865416483034\n",
      "name :  staton\n",
      "distance  0.8938867837970622\n",
      "name :  Deyn\n",
      "distance  0.30571698154545834\n",
      "name :  Devgn\n",
      "distance  0.9748616460853747\n",
      "name :  Hodge\n",
      "distance  1.0945250559177562\n",
      "name :  Kumar\n",
      "distance  0.8092348213310246\n",
      "name :  Fast\n",
      "distance  0.8432310605802651\n",
      "name :  Daddario\n",
      "distance  0.8718128224229162\n",
      "Hi! Deyn, L2 distance: 0.30571698154545834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.30571698154545834, 'Deyn')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_face(image_path = \"./siamese dataset/Agyness_Deyn/19.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  buckley\n",
      "distance  0.957624882917737\n",
      "name :  amir\n",
      "distance  0.9413696593280567\n",
      "name :  staton\n",
      "distance  0.9590817559534535\n",
      "name :  Deyn\n",
      "distance  1.0818515569973681\n",
      "name :  Devgn\n",
      "distance  0.749654571058605\n",
      "name :  Hodge\n",
      "distance  0.27392696470312194\n",
      "name :  Kumar\n",
      "distance  0.965175565814752\n",
      "name :  Fast\n",
      "distance  1.0463017424335361\n",
      "name :  Daddario\n",
      "distance  1.0514898727311277\n",
      "Hi! Hodge, L2 distance: 0.27392696470312194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.27392696470312194, 'Hodge')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_face(image_path = \"./siamese dataset/Aldis_Hodge/28.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  buckley\n",
      "distance  0.8154795018897328\n",
      "name :  amir\n",
      "distance  0.7258255747435582\n",
      "name :  staton\n",
      "distance  0.9104891527828546\n",
      "name :  Deyn\n",
      "distance  0.8500959922074564\n",
      "name :  Devgn\n",
      "distance  0.7534095941712102\n",
      "name :  Hodge\n",
      "distance  0.8904417070580244\n",
      "name :  Kumar\n",
      "distance  0.5014233887428697\n",
      "name :  Fast\n",
      "distance  0.9202106911060706\n",
      "name :  Daddario\n",
      "distance  1.0004876666971745\n",
      "Hi! Kumar, L2 distance: 0.5014233887428697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5014233887428697, 'Kumar')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_face(image_path = \"./siamese dataset/Akshay_Kumar/44.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  buckley\n",
      "distance  0.9327600388499849\n",
      "name :  amir\n",
      "distance  0.9867280738866282\n",
      "name :  staton\n",
      "distance  0.8300859241503626\n",
      "name :  Deyn\n",
      "distance  0.9154851717490674\n",
      "name :  Devgn\n",
      "distance  1.0065891988981432\n",
      "name :  Hodge\n",
      "distance  1.111129497031955\n",
      "name :  Kumar\n",
      "distance  0.9711824594471692\n",
      "name :  Fast\n",
      "distance  0.4507520346859727\n",
      "name :  Daddario\n",
      "distance  0.871149132771125\n",
      "Hi! Fast, L2 distance: 0.4507520346859727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4507520346859727, 'Fast')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_face(image_path = \"./siamese dataset/Alexia_Fast/17.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  buckley\n",
      "distance  0.9062719686840376\n",
      "name :  amir\n",
      "distance  0.9194762018726679\n",
      "name :  staton\n",
      "distance  0.8834574824997554\n",
      "name :  Deyn\n",
      "distance  0.8003598374684854\n",
      "name :  Devgn\n",
      "distance  1.0291756034279715\n",
      "name :  Hodge\n",
      "distance  1.0831327946020117\n",
      "name :  Kumar\n",
      "distance  1.0006629672789935\n",
      "name :  Fast\n",
      "distance  0.7611308892161551\n",
      "name :  Daddario\n",
      "distance  0.3275074120104966\n",
      "Hi! Daddario, L2 distance: 0.3275074120104966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3275074120104966, 'Daddario')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_face(image_path = \"./siamese dataset/Alexandra_Daddario/0.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
